{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NLP Leaderboards #\n",
    "\n",
    "We want to take NLP papers and assign them to a leaderboard by task (T), dataset (D), and evaluation metric (M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train df:  13260\n",
      "Size of test df:  12636\n",
      "Size of train df:  371\n",
      "Size of test df:  325\n"
     ]
    }
   ],
   "source": [
    "# load train/test splits\n",
    "# train_fn = \"../../data/exp1/train_positive.tsv\"\n",
    "# test_fn = \"../../data/exp1/test_positive.tsv\"\n",
    "train_fn = \"../../data/exp1/ablationfull/train.tsv\"\n",
    "test_fn = \"../../data/exp1/ablationfull/test.tsv\"\n",
    "\n",
    "\n",
    "tmp_train_df = pd.read_csv(train_fn, sep='\\t', header=None, names=['T_F', 'file', 'label', 'all_text'])\n",
    "tmp_test_df = pd.read_csv(test_fn, sep='\\t', header=None, names=['T_F', 'file', 'label', 'all_text'])\n",
    "\n",
    "print(\"Size of train df: \", tmp_train_df.shape[0])\n",
    "print(\"Size of test df: \", tmp_test_df.shape[0])\n",
    "\n",
    "# remove false labels, not needed for multiclass classification\n",
    "tmp_train_df.drop(tmp_train_df[tmp_train_df['T_F'] == False].index, inplace=True)\n",
    "tmp_test_df.drop(tmp_test_df[tmp_test_df['T_F'] == False].index, inplace=True)\n",
    "\n",
    "print(\"Size of train df: \", tmp_train_df.shape[0])\n",
    "print(\"Size of test df: \", tmp_test_df.shape[0])\n",
    "#print(train_df[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files:  127\n",
      "Test files:  162\n",
      "['relation prediction, FB15K-237, H@1', 'relation prediction, FB15K-237, H@10', 'relation prediction, WN18RR, H@10', 'relation prediction, WN18RR, H@1', 'relation prediction, FB15K-237, MRR', 'relation prediction, WN18RR, MRR']\n"
     ]
    }
   ],
   "source": [
    "# loop over rows and merge labels for same instances\n",
    "unk_limit = 3\n",
    "unk_seen = 0\n",
    "train_instance_d = {}\n",
    "for index, row in tmp_train_df.iterrows():\n",
    "    if row['label'] == 'unknow':\n",
    "        if unk_seen < unk_limit:\n",
    "            unk_seen += 1\n",
    "        else:\n",
    "            continue  # don't train on unknown labels\n",
    "    if row['file'] in train_instance_d:\n",
    "        if row['all_text'] in train_instance_d[row['file']]:\n",
    "            train_instance_d[row['file']][row['all_text']].append(row['label'])\n",
    "        else:\n",
    "            assert False, \"All files should match one and only one text.\"\n",
    "            train_instance_d[row['file']][row['all_text']] = [row['label']]\n",
    "    else:\n",
    "        train_instance_d[row['file']] = {row['all_text']: [row['label']]}\n",
    "\n",
    "# loop over rows and merge labels for same instances\n",
    "test_instance_d = {}\n",
    "for index, row in tmp_test_df.iterrows():\n",
    "    if row['file'] in test_instance_d:\n",
    "        if row['all_text'] in test_instance_d[row['file']]:\n",
    "            test_instance_d[row['file']][row['all_text']].append(row['label'])\n",
    "        else:\n",
    "            assert False, \"All files should match one and only one text.\"\n",
    "            test_instance_d[row['file']][row['all_text']] = [row['label']]\n",
    "    else:\n",
    "        test_instance_d[row['file']] = {row['all_text']: [row['label']]}\n",
    "\n",
    "print(\"Train files: \", len(train_instance_d))\n",
    "print(\"Test files: \", len(test_instance_d))\n",
    "# print(\"Train instances: \", sum([len(v.items()) for k,v in train_instance_d.items()]))\n",
    "# print(\"Test instances: \", sum([len(v.items()) for k,v in test_instance_d.items()]))\n",
    "print(train_instance_d['trouillon16.pdf']['Complex Embeddings for Simple Link Prediction In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks. 1 In order to evaluate our proposal, we conducted experiments on both synthetic and real datasets The synthetic dataset is based on relations that are either symmetric or antisymmetric, whereas the real datasets comprise different types of relations found in different, standard KBs Dataset We next evaluate the performance of our model on the FB15K and WN18 datasets summarizes the metadata of the two datasets Both datasets contain only positive triples For evaluation, we measure the quality of the ranking of each test triple among all possible subject and object substitutions : r(s , o) and r(s, o ), ∀s , ∀o ∈ E Mean Reciprocal Rank (MRR) and Hits at mare the standard evaluation measures for these datasets and come in two flavours: raw and filtered) We report both filtered and raw MRR, and filtered Hits at 1, 3 and 10 in for the evaluated models Furthermore, we chose TransE, DistMult Table 3. Number of entities, relations, and observed triples in each split for the FB15K and WN18 datasets. |R| Table 2. Filtered and Raw Mean Reciprocal Rank (MRR) for the models tested on the FB15K and WN18 datasets. Hits@m metrics are filtered. *Results reported from (Nickel et al., 2016b) for HolE model. 1 FB15K 3 Filter WN18 Hits at Raw MRR 10 Table 4. Filtered Mean Reciprocal Rank (MRR) for the models tested on each relation of the Wordnet dataset (WN18). ComplEx DistMult TransE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(labels):\n",
    "    tasks = set()\n",
    "    datasets = set()\n",
    "    metrics = set()\n",
    "    for label in labels:\n",
    "        if label == \"unknow\":\n",
    "            task, dataset, metric = label, label, label\n",
    "        else:\n",
    "            try:\n",
    "                task, dataset, metric = label.split(',')\n",
    "            except ValueError:\n",
    "                print(\"Unable to parse label: \", label)\n",
    "        tasks.add(task.strip())\n",
    "        datasets.add(dataset.strip())\n",
    "        metrics.add(metric.strip())\n",
    "    return tasks, datasets, metrics\n",
    "        \n",
    "# convert to dictionaries for creating new dataframe\n",
    "train_d = {'file':[], 'all_text':[], 'task':[], 'dataset':[], 'metric':[]}\n",
    "test_d = {'file':[], 'all_text':[], 'task':[], 'dataset':[], 'metric':[]}\n",
    "\n",
    "for f,t_d in train_instance_d.items():\n",
    "    assert len(t_d) == 1, \"Should only be one entry in this dict.\"\n",
    "    for t, labels in t_d.items():  # should only be one\n",
    "        train_d['file'].append(f)\n",
    "        train_d['all_text'].append(t)\n",
    "        tasks, datasets, metrics = parse_labels(labels)\n",
    "        train_d['task'].append(tasks)\n",
    "        train_d['dataset'].append(datasets)\n",
    "        train_d['metric'].append(metrics)\n",
    "        \n",
    "for f,t_d in test_instance_d.items():\n",
    "    assert len(t_d) == 1, \"Should only be one entry in this dict.\"\n",
    "    for t, labels in t_d.items():  # should only be one\n",
    "        test_d['file'].append(f)\n",
    "        test_d['all_text'].append(t)\n",
    "        tasks, datasets, metrics = parse_labels(labels)\n",
    "        test_d['task'].append(tasks)\n",
    "        test_d['dataset'].append(datasets)\n",
    "        test_d['metric'].append(metrics)\n",
    "        \n",
    "train_df = pd.DataFrame(data=train_d)\n",
    "test_df = pd.DataFrame(data=test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Files:  127\n",
      "Tasks:  19\n",
      "Datasets:  45\n",
      "Metrics:  31\n",
      "Test:\n",
      "Files:  162\n",
      "Tasks:  19\n",
      "Datasets:  45\n",
      "Metrics:  31\n"
     ]
    }
   ],
   "source": [
    "# print stats on train and test sets?\n",
    "print(\"Train:\")\n",
    "print(\"Files: \", train_df['file'].nunique())\n",
    "print(\"Tasks: \", len(set([t for sublist in train_df['task'].tolist() for t in sublist])))\n",
    "print(\"Datasets: \", len(set([t for sublist in train_df['dataset'].tolist() for t in sublist])))\n",
    "print(\"Metrics: \", len(set([t for sublist in train_df['metric'].tolist() for t in sublist])))\n",
    "print(\"Test:\")\n",
    "print(\"Files: \", test_df['file'].nunique())\n",
    "print(\"Tasks: \", len(set([t for sublist in test_df['task'].tolist() for t in sublist])))\n",
    "print(\"Datasets: \", len(set([t for sublist in test_df['dataset'].tolist() for t in sublist])))\n",
    "print(\"Metrics: \", len(set([t for sublist in test_df['metric'].tolist() for t in sublist])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  4349\n",
      "Number of (train) samples:  127\n"
     ]
    }
   ],
   "source": [
    "# apply tfidfvectorizer to get features\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=False, max_df=0.95)\n",
    "# fit-transform on all data\n",
    "#all_data = np.concatenate([train_df['all_text'].values, test_df['all_text'].values])\n",
    "#all_data = train_df['all_text'].values\n",
    "#train_len = len(train_df['all_text'])\n",
    "#x_train = all_x[:train_len]\n",
    "#x_test = all_x[train_len:]\n",
    "\n",
    "# fit on train\n",
    "vectorizer = vectorizer.fit(train_df['all_text'].values)\n",
    "x_train = vectorizer.transform(train_df['all_text'].values)\n",
    "x_test = vectorizer.transform(test_df['all_text'].values)\n",
    "print(\"Number of features: \", x_train.shape[1])\n",
    "print(\"Number of (train) samples: \", x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get instance labels: multilabel or not?\n",
    "# task, data, and metrics label\n",
    "le = {}  # dict for label encoders\n",
    "y = {}  # dict for labels\n",
    "y_test = {}\n",
    "unk_index = {}\n",
    "for label in ['task', 'dataset', 'metric']:\n",
    "    # old single label case\n",
    "#     le[label] = LabelEncoder().fit(train_df[label].tolist() + test_df[label].tolist())\n",
    "#     y[label] = le[label].transform(train_df[label].tolist())\n",
    "#     y_test[label] = le[label].transform(test_df[label].tolist())\n",
    "    # multilabel\n",
    "    le[label] = MultiLabelBinarizer().fit(train_df[label].tolist() + test_df[label].tolist())\n",
    "    y[label] = le[label].transform(train_df[label].tolist())\n",
    "    y_test[label] = le[label].transform(test_df[label].tolist())\n",
    "    unk_index[label] = np.nonzero(le[label].classes_ == 'unknow')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (127, 4349) (162, 4349)\n",
      "y: (127, 19) (162, 19)\n",
      "['amr parsing' 'ccg supertagging' 'chunking' 'constituency parsing'\n",
      " 'dependency parsing' 'language modeling' 'machine translation'\n",
      " 'named entity recognition' 'part-of-speech tagging' 'question answering'\n",
      " 'relation prediction' 'relationship extraction' 'sentiment analysis'\n",
      " 'summarization' 'taxonomy learning' 'text classification' 'unknow'\n",
      " 'word segmentation' 'word sense disambiguation']\n",
      "16\n",
      "['1B Words / Google Billion Word benchmark' 'AG News' 'CCGBank'\n",
      " 'CNN / Daily Mail (Anonymized version)'\n",
      " 'CNN / Daily Mail (Non-anonymized version)' 'Chinese Treebank 6'\n",
      " 'CoNLL 2003 (English)' 'DBpedia' 'DUC 2004 Task 1' 'FB15K-237' 'Gigaword'\n",
      " 'Hutter Prize' 'IMDb' 'LDC2014T12' 'LDC2015E86' 'MSR'\n",
      " 'New York Times Corpus' 'Ontonotes v5 (English)' 'PKU' 'Penn Treebank'\n",
      " 'Quasar' 'SQuAD' 'SST-2' 'SUBJ' 'SearchQA' 'SemEval 2007' 'SemEval 2013'\n",
      " 'SemEval 2015' 'SemEval 2018' 'SemEval-2010 Task 8'\n",
      " 'SemEval-2014 Task 4 subtask 2 Aspect Term Polarity' 'Senseval 2'\n",
      " 'Senseval 3' 'TREC' 'Text8' 'VLSP 2013 POS tagging shared task'\n",
      " 'VLSP 2013 word segmentation shared task' 'VLSP 2016 NER shared task'\n",
      " 'WMT 2014 EN-DE' 'WMT 2014 EN-FR' 'WN18RR' 'WikiText-103' 'WikiText-2'\n",
      " 'benchmark Vietnamese dependency treebank VnDT' 'unknow']\n",
      "44\n",
      "['Accuracy' 'BLEU' 'Bit per Character (BPC)' 'EM' 'EM (Quasar-T)' 'Error'\n",
      " 'F1' 'F1 (Quasar-T)' 'F1 on Full' 'F1 on Newswire' 'H@1' 'H@10' 'LAS'\n",
      " 'Laptop (acc)' 'MAP' 'MRR' 'N-gram F1' 'Number of params' 'P@10%' 'P@5'\n",
      " 'POS' 'ROUGE-1' 'ROUGE-2' 'ROUGE-L' 'Restaurant (acc)' 'Smatch'\n",
      " 'Test perplexity' 'UAS' 'Unigram Acc' 'Validation perplexity' 'unknow']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# print shapes, sizes\n",
    "print(\"X:\", x_train.shape, x_test.shape)\n",
    "print(\"y:\", y['task'].shape, y_test['task'].shape)\n",
    "for label in ['task', 'dataset', 'metric']:\n",
    "    print(le[label].classes_)\n",
    "    print(unk_index[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for  task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for  dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for  metric\n"
     ]
    }
   ],
   "source": [
    "# cross validation to find good hyperparameters\n",
    "# random shuffling might not be ideal for splitting this data, but I don't think we have another option\n",
    "\n",
    "# simple_clf = RandomForestClassifier()\n",
    "simple_clf = LogisticRegression(solver=\"saga\", multi_class=\"multinomial\")\n",
    "\n",
    "clf = {}  # dict for classifier (by label)\n",
    "for label in ['task', 'dataset', 'metric']:\n",
    "    clf[label] = MultiOutputClassifier(simple_clf, n_jobs=-1).fit(x_train, y[label])\n",
    "#     clf[label] = RandomForestClassifier(n_jobs=-1).fit(x_train, y[label])\n",
    "    print(\"Trained model for \", label)\n",
    "#     print(clf[label].get_params())\n",
    "#     print(clf[label].C_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:  Universal Sentence Encoder We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants , we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with base-lines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data fora transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub. Otherwise, hyperparameters are tuned by crossvalidation on the task training data when available or the evaluation test data when neither training nor dev data are provided Training repeats ten times for each transfer task model with different randomly initialized weights and we report evaluation results by averaging across runs To assess bias in our encoding models, we evaluate the strength of various associations learned by our model on WEAT word lists Table 1: Transfer task evaluation sets 1 , 821 Dev Test 1 , 379 ) . Table 2: Model performance on transfer tasks. USE T is the universal sentence encoder (USE) using Transformer. USE D is the universal encoder DAN model. Models tagged with Baselines with No Transfer Learning Sentence & Word Embedding Transfer Learning - Sentence Embedding Transfer Learning Word Embedding Transfer Learning MR SST STS Bench MPQA TREC SUBJ CR Table 3: Task performance on SST for varying amounts of training data. SST 67.3k represents the full training set. Using only 1,000 examples for training, transfer learning from USE T is able to obtain performance that rivals many of the other models trained on the full 67.3 thousand example training set. Baselines with No Transfer Learning Sentence Embedding Transfer Learning Word Embedding Transfer Learning Sentence & Word Embedding Transfer Learning Table 4: Word Embedding Association Tests (WEAT) for GloVe\n",
      "Some features: \n",
      "Gold label:  {'sentiment analysis', 'text classification'}  (binary)  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "Prediction:  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Prediction prob.:  [array([[0.81897762, 0.18102238]]), array([[0.83864147, 0.16135853]]), array([[0.85280783, 0.14719217]]), array([[0.83725301, 0.16274699]]), array([[0.78258229, 0.21741771]]), array([[0.77808625, 0.22191375]]), array([[0.84537876, 0.15462124]]), array([[0.70555977, 0.29444023]]), array([[0.7363235, 0.2636765]]), array([[0.7637619, 0.2362381]]), array([[0.84860662, 0.15139338]]), array([[0.7898474, 0.2101526]]), array([[0.72975514, 0.27024486]]), array([[0.75103441, 0.24896559]]), array([[0.82693433, 0.17306567]]), array([[0.78951778, 0.21048222]]), array([[0.84940179, 0.15059821]]), array([[0.81529044, 0.18470956]]), array([[0.8399428, 0.1600572]])]\n",
      "Gold label:  {'SUBJ', 'TREC'}  (binary)  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "Prediction:  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0]]\n",
      "Prediction prob.:  [array([[0.84929693, 0.15070307]]), array([[0.83556462, 0.16443538]]), array([[0.83864147, 0.16135853]]), array([[0.82663019, 0.17336981]]), array([[0.79868677, 0.20131323]]), array([[0.84264156, 0.15735844]]), array([[0.73499564, 0.26500436]]), array([[0.83556462, 0.16443538]]), array([[0.84137724, 0.15862276]]), array([[0.84860662, 0.15139338]]), array([[0.82245203, 0.17754797]]), array([[0.83839063, 0.16160937]]), array([[0.82390421, 0.17609579]]), array([[0.84262198, 0.15737802]]), array([[0.85102139, 0.14897861]]), array([[0.85616094, 0.14383906]]), array([[0.85063512, 0.14936488]]), array([[0.84933014, 0.15066986]]), array([[0.8562254, 0.1437746]]), array([[0.61900953, 0.38099047]]), array([[0.86402769, 0.13597231]]), array([[0.78559944, 0.21440056]]), array([[0.83617546, 0.16382454]]), array([[0.83499331, 0.16500669]]), array([[0.85028858, 0.14971142]]), array([[0.84952135, 0.15047865]]), array([[0.8399428, 0.1600572]]), array([[0.84025824, 0.15974176]]), array([[0.82545552, 0.17454448]]), array([[0.80644449, 0.19355551]]), array([[0.83529166, 0.16470834]]), array([[0.84025824, 0.15974176]]), array([[0.84007661, 0.15992339]]), array([[0.80826948, 0.19173052]]), array([[0.83837997, 0.16162003]]), array([[0.83693454, 0.16306546]]), array([[0.84996642, 0.15003358]]), array([[0.84759657, 0.15240343]]), array([[0.84544547, 0.15455453]]), array([[0.85115965, 0.14884035]]), array([[0.8488414, 0.1511586]]), array([[0.84052899, 0.15947101]]), array([[0.83121978, 0.16878022]]), array([[0.8403811, 0.1596189]]), array([[0.84940179, 0.15059821]])]\n",
      "Gold label:  {'Accuracy', 'Error'}  (binary)  [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Prediction:  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Prediction prob.:  [array([[0.61064259, 0.38935741]]), array([[0.84537876, 0.15462124]]), array([[0.82654396, 0.17345604]]), array([[0.78870141, 0.21129859]]), array([[0.86382095, 0.13617905]]), array([[0.78915502, 0.21084498]]), array([[0.53143465, 0.46856535]]), array([[0.86382095, 0.13617905]]), array([[0.85611642, 0.14388358]]), array([[0.84895177, 0.15104823]]), array([[0.84860662, 0.15139338]]), array([[0.84860662, 0.15139338]]), array([[0.80908308, 0.19091692]]), array([[0.83525374, 0.16474626]]), array([[0.82693433, 0.17306567]]), array([[0.7998316, 0.2001684]]), array([[0.85028858, 0.14971142]]), array([[0.796617, 0.203383]]), array([[0.85051802, 0.14948198]]), array([[0.82567893, 0.17432107]]), array([[0.84409665, 0.15590335]]), array([[0.7518309, 0.2481691]]), array([[0.75137378, 0.24862622]]), array([[0.75151953, 0.24848047]]), array([[0.83529166, 0.16470834]]), array([[0.85017661, 0.14982339]]), array([[0.79441973, 0.20558027]]), array([[0.78107905, 0.21892095]]), array([[0.85028858, 0.14971142]]), array([[0.81998718, 0.18001282]]), array([[0.84978522, 0.15021478]])]\n"
     ]
    }
   ],
   "source": [
    "# run prediction on a couple of examples from the test data\n",
    "print(\"Raw text: \", test_df['all_text'][0])\n",
    "print(\"Some features: \")\n",
    "for label in ['task', 'dataset', 'metric']:\n",
    "    print(\"Gold label: \", test_df[label][0], \" (binary) \", y_test[label][0])\n",
    "    print(\"Prediction: \", clf[label].predict(x_test[0]))\n",
    "    print(\"Prediction prob.: \", clf[label].predict_proba(x_test[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03508771929824561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesj/miniconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018518518518518517\n",
      "0.08143839238498148\n"
     ]
    }
   ],
   "source": [
    "# run prediction on all test data\n",
    "pred = {}\n",
    "pred_prob = {}\n",
    "for label in ['task', 'dataset', 'metric']:\n",
    "    pred[label] = clf[label].predict(x_test)\n",
    "    pred_prob[label] = clf[label].predict_proba(x_test)\n",
    "    score = f1_score(y_test[label], pred[label], average='macro')\n",
    "    print(score)\n",
    "#     conf_mat = confusion_matrix(metric_y, train_pred)\n",
    "#     np.savetxt(\"/tmp/foo.csv\", conf_mat, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False False False  True False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "   True False False False False False False]\n",
      " [False False False False  True False False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False  True False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False False]]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False  True False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False  True False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False  True False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False  True False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False  True False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]]\n",
      "[[False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_pred(pred, pred_prob):\n",
    "    update_pred = {}\n",
    "    for label in ['task', 'dataset', 'metric']:\n",
    "        mask = np.sum(pred[label], axis=1) > 0\n",
    "        pred_prob_np = None\n",
    "        for i in pred_prob[label]:  # use for-loop to make sure all have the right shape\n",
    "            if i.shape[1] == 1:\n",
    "                i = np.concatenate((i,np.zeros((i.shape[0],1))), axis=1)\n",
    "            assert i.shape[1] == 2, \"Only expecting 2 columns (at this point) but we have shape: %s\" % str(i.shape)\n",
    "            if pred_prob_np is None:\n",
    "                pred_prob_np = i\n",
    "            else:\n",
    "                pred_prob_np = np.concatenate((pred_prob_np, i))\n",
    "        pred_prob_np = pred_prob_np.reshape((len(pred_prob[label]),-1,2))\n",
    "        am = np.argmax(pred_prob_np, axis=0)[:,1]  # need max of second column, prob label is true\n",
    "        oh = np.zeros(pred[label].shape)\n",
    "        oh[np.arange(pred[label].shape[0]), am] = 1\n",
    "        print(((oh+pred[label])>0)[:5])\n",
    "        update_pred[label] = (oh + pred[label])>0\n",
    "    return update_pred\n",
    "\n",
    "update_pred = update_pred(pred, pred_prob)\n",
    "update_pred['metric']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to CSV for evaluation\n",
    "# TODO vectorize or use new dataframe\n",
    "# want to write paper name, task, dataset, evaluation metric, score\n",
    "#for x in test_df['file'].tolist():\n",
    "#    print \n",
    "csv_df = test_df['file'].copy()\n",
    "for label in ['task', 'dataset', 'metric']:\n",
    "    csv_df = pd.concat((csv_df, pd.Series(le[label].inverse_transform(update_pred[label]))), axis=1)\n",
    "csv_df['score'] = '0.0'\n",
    "csv_df.columns = ['file', 'task', 'dataset', 'metric', 'score']\n",
    "csv_df.to_csv(\"/tmp/output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
